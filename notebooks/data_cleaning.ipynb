{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning:\n",
      "                         Transaction ID                           Customer ID  \\\n",
      "0  539db039-37c0-4f91-b6fa-079af50ee7fd  c3b9ac53-4a42-46ac-9850-f46605e4e94a   \n",
      "1  2c37f0fc-0ca2-4f93-97bf-659fa96788f1  1b2acf0b-cb58-44c4-a272-6f01d5b0116e   \n",
      "2  037d7859-03e2-45a0-ad46-80d8ab92fbd4  4a636dcd-686b-45fc-ba6e-54056dc273fb   \n",
      "3  84d6a5ff-a05c-4d7c-9fb5-1106a1594a97  b2cc871e-3d07-4136-bea9-782d5a6e8dc9   \n",
      "4  5c899683-d731-4c29-a7c0-715f5c8368da  d3a7f85b-0d5d-42b2-bae7-d221da5d861b   \n",
      "\n",
      "  Transaction Date Product Category   Price  Quantity Payment Method  \\\n",
      "0       2024-04-13      Electronics  370.81       3.0         PayPal   \n",
      "1       2023-07-10           Sports  119.51       4.0     Debit Card   \n",
      "2       2025-01-29      Electronics  219.32       2.0         PayPal   \n",
      "3       2023-03-25            Books   76.09       NaN     Debit Card   \n",
      "4       2023-09-13   Home & Kitchen   59.01       1.0         PayPal   \n",
      "\n",
      "  Shipping Status  Customer Rating  \n",
      "0         Shipped              2.0  \n",
      "1       Delivered              1.0  \n",
      "2         Shipped              2.0  \n",
      "3         Pending              3.0  \n",
      "4         Shipped              3.0  \n",
      "\n",
      "✅ No blank cells found in the dataset.\n",
      "\n",
      "After Cleaning:\n",
      "                         Transaction ID                           Customer ID  \\\n",
      "0  539db039-37c0-4f91-b6fa-079af50ee7fd  c3b9ac53-4a42-46ac-9850-f46605e4e94a   \n",
      "1  2c37f0fc-0ca2-4f93-97bf-659fa96788f1  1b2acf0b-cb58-44c4-a272-6f01d5b0116e   \n",
      "2  037d7859-03e2-45a0-ad46-80d8ab92fbd4  4a636dcd-686b-45fc-ba6e-54056dc273fb   \n",
      "3  84d6a5ff-a05c-4d7c-9fb5-1106a1594a97  b2cc871e-3d07-4136-bea9-782d5a6e8dc9   \n",
      "4  5c899683-d731-4c29-a7c0-715f5c8368da  d3a7f85b-0d5d-42b2-bae7-d221da5d861b   \n",
      "\n",
      "  Transaction Date Product Category   Price  Quantity Payment Method  \\\n",
      "0       2024-04-13      Electronics  370.81       3.0         PayPal   \n",
      "1       2023-07-10           Sports  119.51       4.0     Debit Card   \n",
      "2       2025-01-29      Electronics  219.32       2.0         PayPal   \n",
      "3       2023-03-25            Books   76.09       1.0     Debit Card   \n",
      "4       2023-09-13   Home & Kitchen   59.01       1.0         PayPal   \n",
      "\n",
      "  Shipping Status  Customer Rating  \n",
      "0         Shipped              2.0  \n",
      "1       Delivered              1.0  \n",
      "2         Shipped              2.0  \n",
      "3         Pending              3.0  \n",
      "4         Shipped              3.0  \n",
      "\n",
      "✅ Data Cleaning Completed! Cleaned file saved at '/Users/yowhenyow/Documents/Codes/ecom-transactions-dataset/data/cleaned_ecom_transactions.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the \"data\" folder (one level up from \"notebooks\")\n",
    "data_folder = os.path.join(os.path.dirname(os.getcwd()), \"data\")\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = os.path.join(data_folder, \"ecom_transactions.csv\")\n",
    "output_file = os.path.join(data_folder, \"cleaned_ecom_transactions.csv\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Display the first few rows before cleaning\n",
    "print(\"Before Cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "### 1. HANDLE MISSING VALUES ###\n",
    "# Convert 'Price' to numeric, setting errors to NaN\n",
    "df[\"Price\"] = pd.to_numeric(df[\"Price\"], errors=\"coerce\")\n",
    "\n",
    "# Fill missing Product Categories with the most common one\n",
    "df.loc[:, \"Product Category\"] = df[\"Product Category\"].fillna(df[\"Product Category\"].mode()[0])\n",
    "\n",
    "# Convert 'Transaction Date' to datetime, forcing errors to NaT\n",
    "df[\"Transaction Date\"] = pd.to_datetime(df[\"Transaction Date\"], errors=\"coerce\")\n",
    "\n",
    "# Convert 'Quantity' to integer (fill NaN with 1, assuming a single order)\n",
    "df.loc[:, \"Quantity\"] = pd.to_numeric(df[\"Quantity\"], errors=\"coerce\").fillna(1).astype(int)\n",
    "\n",
    "# Use linear regression to fill missing Price values\n",
    "valid_rows = df.dropna(subset=[\"Price\"])  # Rows with known Price\n",
    "missing_rows = df[df[\"Price\"].isna()]  # Rows with missing Price\n",
    "\n",
    "if not missing_rows.empty:\n",
    "    # Prepare features for regression\n",
    "    X = valid_rows[[\"Quantity\"]]\n",
    "    y = valid_rows[\"Price\"]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict missing Prices\n",
    "    df.loc[df[\"Price\"].isna(), \"Price\"] = model.predict(missing_rows[[\"Quantity\"]])\n",
    "\n",
    "### 2. REMOVE DUPLICATES ###\n",
    "df = df.drop_duplicates(subset=[\"Transaction ID\"], keep=\"first\")\n",
    "\n",
    "### 3. HANDLE OUTLIERS ###\n",
    "# Remove extreme outliers in Price (above 99th percentile)\n",
    "upper_limit = df[\"Price\"].quantile(0.99)\n",
    "df = df[df[\"Price\"] <= upper_limit]\n",
    "\n",
    "# Remove extreme Quantity outliers (above 1000)\n",
    "df = df[df[\"Quantity\"] <= 1000]\n",
    "\n",
    "### 4. FIX CATEGORICAL VALUES ###\n",
    "# Standardize Product Category names (capitalize each word)\n",
    "df.loc[:, \"Product Category\"] = df[\"Product Category\"].str.title()\n",
    "\n",
    "### 5. REMOVE INCORRECT VALUES ###\n",
    "# Drop rows where Price or Quantity is negative\n",
    "df = df[(df[\"Price\"] > 0) & (df[\"Quantity\"] > 0)]\n",
    "\n",
    "# Fill missing Customer Ratings with the median value\n",
    "df.loc[:, \"Customer Rating\"] = df[\"Customer Rating\"].fillna(df[\"Customer Rating\"].median())\n",
    "\n",
    "# Fill missing Payment Methods with the most common one\n",
    "df.loc[:, \"Payment Method\"] = df[\"Payment Method\"].fillna(df[\"Payment Method\"].mode()[0])\n",
    "\n",
    "### 6. CHECK FOR BLANK VALUES ###\n",
    "def check_blank_cells(df):\n",
    "    \"\"\"Checks for blank cells in the dataset and prints the results.\"\"\"\n",
    "    blank_counts = (df == \"\").sum() + (df == \" \").sum()\n",
    "    blank_columns = blank_counts[blank_counts > 0]\n",
    "    \n",
    "    if blank_columns.empty:\n",
    "        print(\"\\n✅ No blank cells found in the dataset.\")\n",
    "    else:\n",
    "        from IPython.display import display  # Import for Jupyter display\n",
    "        print(\"\\n⚠️ Blank cells detected in the following columns:\")\n",
    "        display(blank_columns.to_frame(name=\"Blank Count\"))  # Better display format\n",
    "\n",
    "# Run the function on the cleaned DataFrame\n",
    "check_blank_cells(df)\n",
    "\n",
    "# Display cleaned dataset\n",
    "print(\"\\nAfter Cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ Data Cleaning Completed! Cleaned file saved at '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
